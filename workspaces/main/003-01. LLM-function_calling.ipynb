{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Korzystanie z API Open AI z użyciem _function calling_\n",
    "\n",
    "Function calling to mechanizm, który pozwala LLMom na wywoływanie zdefiniowanych funkcji w odpowiedzi na zapytania użytkownika. Dzięki temu modele mogą wykonywać bardziej złożone operacje, takie jak pobieranie danych z zewnętrznych API, przetwarzanie informacji czy wykonywanie obliczeń. Mechanizm ten umożliwia integrację modeli LLM z różnymi narzędziami i usługami, co zwiększa ich funkcjonalność i zakres zastosowań.\n",
    "\n",
    "Więcej informacji, w tym na temat konfiguracji, użycia oraz przykłady, znajdziecie w [dokumentacji](https://platform.openai.com/docs/guides/function-calling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from helpers import parse_nested_json # funkcja która parsuje zagnieżdżone jsony, aby potem było można je wypisać w dobrze sformatowany sposób"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcja pobierająca współrzędne geograficzne dla danej nazwy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geolocation(location):\n",
    "    \"\"\"\n",
    "    Pobiera współrzędne geograficzne oraz dane lokalizacyjne.\n",
    "\n",
    "    Parametry:\n",
    "    location (str): Nazwa lokalizacji, dla której chcemy uzyskać współrzędne geograficzne.\n",
    "\n",
    "    Zwraca:\n",
    "    dict: Dane lokalizacyjne w formacie JSON.\n",
    "    \"\"\"\n",
    "    # Definiowanie endpointu i parametrów dla API OpenStreetMap Nominatim\n",
    "    geocode_endpoint = \"https://nominatim.openstreetmap.org/search\"\n",
    "    geocode_params = {\n",
    "        \"q\": location,\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "\n",
    "    # Nagłówek User-Agent jest wymagany do korzystania z tego API\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Python script\"\n",
    "    }\n",
    "\n",
    "    # Wykonanie zapytania\n",
    "    geocode_response = requests.get(geocode_endpoint, params=geocode_params, headers=headers)\n",
    "\n",
    "    # Wyciągnięcie współrzędnych geograficznych\n",
    "    geocode_data = geocode_response.json()\n",
    "    \n",
    "    # Zwrócenie tylko nazwy miejsca, szerokości i długości geograficznej\n",
    "    simplified_data = {\n",
    "        \"name\": geocode_data[0][\"display_name\"],\n",
    "        \"latitude\": geocode_data[0][\"lat\"],\n",
    "        \"longitude\": geocode_data[0][\"lon\"]\n",
    "    }\n",
    "    return simplified_data\n",
    "\n",
    "# Przykład użycia funkcji\n",
    "geolocation_data = get_geolocation(\"Poznań\")\n",
    "print(json.dumps(geolocation_data, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcja pobierająca informacje o pogodzie dla podanych współrzędnych geograficznych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wind_direction(degrees):\n",
    "    \"\"\"\n",
    "    Konwertuje kierunek wiatru z stopni na nazwy kierunków.\n",
    "\n",
    "    Parametry:\n",
    "    degrees (float): Kierunek wiatru w stopniach.\n",
    "\n",
    "    Zwraca:\n",
    "    str: Nazwa kierunku wiatru.\n",
    "    \"\"\"\n",
    "    directions = ['N', 'NNE', 'NE', 'ENE', 'E', 'ESE', 'SE', 'SSE',\n",
    "                  'S', 'SSW', 'SW', 'WSW', 'W', 'WNW', 'NW', 'NNW']\n",
    "    index = int((degrees + 11.25) // 22.5) % 16\n",
    "    return directions[index]\n",
    "\n",
    "def get_current_weather(latitude, longitude):\n",
    "    \"\"\"\n",
    "    Pobiera aktualne dane pogodowe dla podanych współrzędnych geograficznych.\n",
    "\n",
    "    Parametry:\n",
    "    latitude (float): Szerokość geograficzna.\n",
    "    longitude (float): Długość geograficzna.\n",
    "\n",
    "    Zwraca:\n",
    "    dict: Dane pogodowe w formacie JSON.\n",
    "    \"\"\"\n",
    "    # Zdefiniowanie endpointu i parametrów dla Open Meteo API\n",
    "    weather_endpoint = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    weather_params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"current_weather\": True\n",
    "    }\n",
    "\n",
    "    # Wykonanie requestu\n",
    "    weather_response = requests.get(weather_endpoint, params=weather_params)\n",
    "\n",
    "    # Wyciągnięcie informacji o pogodzie\n",
    "    weather_data = weather_response.json()\n",
    "\n",
    "    simplified_weather = {\n",
    "        \"temperature\": f\"{weather_data['current_weather']['temperature']} °C\",\n",
    "        \"wind_speed\": f\"{weather_data['current_weather']['windspeed']} km/h\",\n",
    "        \"wind_direction\": get_wind_direction(weather_data['current_weather']['winddirection']),\n",
    "        \"is_day\": \"day\" if weather_data['current_weather']['is_day'] else \"night\"\n",
    "    }\n",
    "\n",
    "    return simplified_weather\n",
    "\n",
    "# Przykład użycia funkcji\n",
    "current_weather = get_current_weather(geolocation_data['latitude'], geolocation_data['longitude'])\n",
    "print(json.dumps(current_weather, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowanie informacji do modelu o tym, jakie funkcje mamy dostępne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista opisów dostępnych funkcji, które pozwalamy modelowi wywołać\n",
    "# Każdy zawiera nazwę funkcji, opis jej działania oraz parametry, które funkcja przyjmuje.\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_geolocation\",\n",
    "            \"description\": \"Pobiera współrzędne geograficzne oraz dane lokalizacyjne.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Nazwa lokalizacji, dla której chcemy uzyskać współrzędne geograficzne.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "                \"additionalProperties\": False\n",
    "            },\n",
    "            \"strict\": True\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Pobiera aktualne dane pogodowe dla podanych współrzędnych geograficznych.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"latitude\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"Szerokość geograficzna lokalizacji dla której pobierana jest pogoda.\"\n",
    "                    },\n",
    "                    \"longitude\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"Długość geograficzna lokalizacji dla której pobierana jest pogoda.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"latitude\", \"longitude\"],\n",
    "                \"additionalProperties\": False\n",
    "            },\n",
    "            \"strict\": True\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcja pomocnicza, która wykonywa wskazaną przez model funkcję - o ile ten o to poprosi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja obsługuje wywołania funkcji na podstawie nazwy funkcji i argumentów.\n",
    "def handle_function_call(function_name, arguments):\n",
    "    print(f\"<function_call> Function: {function_name}, Arguments: {arguments}\")\n",
    "\n",
    "    arguments = json.loads(arguments)\n",
    "\n",
    "    if function_name == \"get_geolocation\":\n",
    "        res = get_geolocation(arguments['location'])\n",
    "        return json.dumps(res)\n",
    "    elif function_name == \"get_current_weather\":\n",
    "        res = get_current_weather(arguments['latitude'], arguments['longitude'])\n",
    "        return json.dumps(res)\n",
    "    else:\n",
    "        return {\"error\": \"Unknown function\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcja pomocnicza, która wyciąga z odpowiedzi modelu które funkcje i z jakimi argumentami mają zostać wykonane, i następnie je wykonuje z użyciem powyższej funkcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_tool_calls(response, messages):\n",
    "    \"\"\"\n",
    "    Wykonuje funkcje zlecone przez model i aktualizuje historię wiadomości.\n",
    "\n",
    "    Parametry:\n",
    "    response (openai.types.chat.chat_completion.ChatCompletion): Odpowiedź od modelu zawierająca zlecenia funkcji.\n",
    "    messages (list): Historia wiadomości.\n",
    "\n",
    "    Zwraca:\n",
    "    list: Zaktualizowana historia wiadomości.\n",
    "    \"\"\"\n",
    "\n",
    "    # dodajemy odpowiedź, w tym ew. prośby o wywołanie funkcji, do historii wiadomości\n",
    "    messages.append(response.choices[0].message.model_dump())\n",
    "\n",
    "    for tool_call in response.choices[0].message.tool_calls:\n",
    "        # pobieramy nazwę funkcji i argumenty z odpowiedzi od modelu\n",
    "        name = tool_call.function.name\n",
    "        args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "        # wywołanie funkcji na podstawie pobranej nazwy funkcji i argumentów\n",
    "        result = handle_function_call(name, json.dumps(args))\n",
    "\n",
    "        # dodajemy wynik funkcji do historii wiadomości\n",
    "        messages.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"content\": result\n",
    "        })\n",
    "\n",
    "    return messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Przesłanie początkowego zapytania do modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Inicjalizacja klienta\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(api_key=api_key) # konfiguracja połączenia z API\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Jesteś pomocnym asystentem.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Opisz jaka jest pogoda w Poznaniu. Czy powinienem wychodzić na spacer w stroju plażowym i okularach przeciwsłonecznych?\"},\n",
    "]\n",
    "\n",
    "# Przykład zapytania do GPT-4o z function callingiem\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    tools=tools, # przekazujemy listę dostępnych funkcji\n",
    "    tool_choice=\"auto\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=16000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wykonanie funkcji zleconych przez model\n",
    "\n",
    "W tym przypadku wiemy, że model zleci wykonanie funkcji pobrania lokalizacji dla Poznania, ponieważ sami określiliśmy jego wejściowe zapytanie. Gdybyśmy oprogramowywali system, w którym użytkownik wprowadza dowolny tekst, nie moglibyśmy tego zakładać - użytkownik może zadać pytanie, do odpowiedzi na które dostępne dla modelu funkcje mogą nie być przydatne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i wywołujemy, aby obsłużyć zlecenia modelu odnośnie wykonania funkcji\n",
    "messages = execute_tool_calls(response, messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podejrzyjmy co teraz jest w messages\n",
    "parsed_data = parse_nested_json(messages)\n",
    "\n",
    "print(json.dumps(parsed_data, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kolejny request do modelu - zwrócenie wyniku funkcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kolejny request, z wynikiem wykonanej funkcji\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=16000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obsługa kolejnej funkcji zleconej przez model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ponownie obsługujemy zlecone przez model wykonania funkcji\n",
    "messages = execute_tool_calls(response, messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podejrzyjmy co teraz jest w messages\n",
    "parsed_data = parse_nested_json(messages)\n",
    "\n",
    "print(json.dumps(parsed_data, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kolejny request do modelu - zwrócenie wyniku kolejnej funkcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kolejny request, z wynikiem kolejnej funkcji\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=16000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ostateczny wynik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zobaczmy co model nam ostatecznie odpowiedział\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A teraz wszystko jako jedna funkcja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_command(user_command):\n",
    "    \"\"\"\n",
    "    Przetwarza polecenie użytkownika z użyciem GPT-4o oraz funkcji get_geolocation i get_current_weather.\n",
    "\n",
    "    Parametry:\n",
    "    user_command (str): Polecenie użytkownika.\n",
    "\n",
    "    Zwraca:\n",
    "    str: Odpowiedź na polecenie użytkownika.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Jesteś pomocnym asystentem.\"},\n",
    "        {\"role\": \"user\", \"content\": user_command}\n",
    "    ]\n",
    "    \n",
    "    while True:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=16000\n",
    "        )\n",
    "        \n",
    "        message = response.choices[0].message\n",
    "        \n",
    "        # Jeśli model żąda wykonania funkcji, wykonujemy je i aktualizujemy historię wiadomości\n",
    "        # (nastąpi kolejne wykonanie pętli zawierające request do modelu, w którym przekażemy wyniki wykonania funkcji)\n",
    "        if getattr(message, \"tool_calls\", None):\n",
    "            messages = execute_tool_calls(response, messages)\n",
    "        else:\n",
    "            # Gdy nie ma już żądań funkcji, zwracamy ostateczną odpowiedź modelu.\n",
    "            return message.content, messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wykonanie funkcji\n",
    "user_command = \"Podaj aktualną pogodę dla Poznania. Czy mam założyć kurtkę?\"\n",
    "# user_command = \"Podaj aktualną pogodę dla współrzędnych: 52 st. 24 min. N 16 st. 55 min. E.\"\n",
    "# user_command = \"ile to jest 2+2?\"\n",
    "\n",
    "response_content, messages = process_user_command(user_command)\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zobaczmy co jest w holistrii wiadomości\n",
    "parsed_data = parse_nested_json(messages)\n",
    "\n",
    "print(json.dumps(parsed_data, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
