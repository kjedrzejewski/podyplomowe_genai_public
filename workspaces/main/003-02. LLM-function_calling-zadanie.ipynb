{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie - Uzycie _function calling_ do obliczeń matematycznych\n",
    "\n",
    "W tym zadaniu będziemy używać OpenAI Function Calling do przekazania możliwości wykonywania obliczeń matematycznych do modelu językowego. Dzięki temu LLM będzie mógł prawidłowo rozwiązywać problemy matematyczne, wykonując obliczenia za pomocą biblioteki mathparse.\n",
    "\n",
    "1. **Cel zadania**: Dać modelowi językowemu możliwość wykonywanie precyzyjnych obliczeń matematycznych.\n",
    "\n",
    "2. **Wymagania techniczne**:\n",
    "    - Biblioteka `mathparse` do parsowania i ewaluacji wyrażeń matematycznych\n",
    "    - API OpenAI (GPT-4o lub podobny model wspierający function calling)\n",
    "\n",
    "3. **Etapy realizacji**:\n",
    "    - Stworzenie funkcji pomocniczej do obliczania wyrażeń matematycznych\n",
    "    - Zdefiniowanie narzędzia (tool) dla modelu GPT\n",
    "    - Implementacja mechanizmu obsługi wywołań funkcji\n",
    "    - Stworzenie interfejsu komunikacji z modelem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from mathparse import mathparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykład użycia _mathparse_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mathparse.parse(\"2 + 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja `calculate()` - Obliczanie wyrażeń matematycznych\n",
    "\n",
    "Funkcja `calculate()` pozwala na wykonywanie obliczeń matematycznych z wyrażeń zapisanych w formie tekstu. Funkcja wykorzystuje bibliotekę `mathparse` do analizy i ewaluacji wyrażeń.\n",
    "\n",
    "#### Przykłady użycia:\n",
    "- Proste obliczenia: \"2 + 2\", \"5 * 3\"\n",
    "- Funkcje matematyczne: \"sin(30)\", \"sqrt(16)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(math_expression):\n",
    "    # ... Wasz kod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definicja narzędzia (tool) dla modelu\n",
    "\n",
    "Ten etap obejmuje utworzenie definicji narzędzia, które zostanie przekazane do modelu GPT jako możliwa do wywołania funkcja. Definicja zawiera:\n",
    "\n",
    "1. **Typ narzędzia** - w tym przypadku \"function\"\n",
    "2. **Metadane funkcji**:\n",
    "    - Nazwa funkcji (`calculate`) - będzie używana przez model do wywołania\n",
    "    - Szczegółowy opis funkcjonalności\n",
    "    - Specyfikacja parametrów w formacie JSON Schema\n",
    "\n",
    "Taka definicja pozwala modelowi zrozumieć:\n",
    "- Kiedy powinien użyć funkcji obliczeniowej\n",
    "- Jakie dane musi przekazać\n",
    "- W jakim formacie powinny być przekazane argumenty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    # ... Wasz kod\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przygotowanie funkcji obsługującej wywołania funkcji\n",
    "\n",
    "Ten etap polega na stworzeniu funkcji, która obsłuży wywołania narzędzi (tool calls) generowane przez model GPT. Funkcja `handle_function_call()` pełni kluczową rolę w całym procesie:\n",
    "\n",
    "1. **Przyjmowanie żądań modelu** - odbiera nazwę funkcji oraz argumenty do wykonania obliczeń\n",
    "2. **Delegowanie wykonania** - wywołuje odpowiednią funkcję (w tym przypadku `calculate()`)\n",
    "3. **Formatowanie odpowiedzi** - przekształca wynik w format zrozumiały dla modelu\n",
    "\n",
    "W tym miejscu możemy też pojawić się:\n",
    "\n",
    "4. **Walidacja danych wejściowych** - sprawdzenie poprawności przekazanych parametrów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja obsługuje wywołania funkcji na podstawie nazwy funkcji i argumentów.\n",
    "def handle_function_call(function_name, arguments):\n",
    "    print(f\"<function_call> Function: {function_name}, Arguments: {arguments}\")\n",
    "\n",
    "    # ... Wasz kod\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniższa funkcja obsłuży wywołania funkcji zlecone przez model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_tool_calls(response, messages):\n",
    "    \"\"\"\n",
    "    Wykonuje funkcje zlecone przez model i aktualizuje historię wiadomości.\n",
    "\n",
    "    Parametry:\n",
    "    response (openai.types.chat.chat_completion.ChatCompletion): Odpowiedź od modelu zawierająca zlecenia funkcji.\n",
    "    messages (list): Historia wiadomości.\n",
    "\n",
    "    Zwraca:\n",
    "    list: Zaktualizowana historia wiadomości.\n",
    "    \"\"\"\n",
    "    # dodajemy odpowiedź, w której mieliśmy prośbę o wywołanie funkcji, do historii wiadomości\n",
    "    messages.append(response.choices[0].message.model_dump())\n",
    "\n",
    "    for tool_call in response.choices[0].message.tool_calls:\n",
    "        # pobieramy nazwę funkcji i argumenty z odpowiedzi od modelu\n",
    "        name = tool_call.function.name\n",
    "        args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "        # wywołanie funkcji na podstawie pobranej nazwy funkcji i argumentów\n",
    "        result = handle_function_call(name, json.dumps(args))\n",
    "\n",
    "        # dodajemy wynik funkcji do historii wiadomości\n",
    "        messages.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"content\": result\n",
    "        })\n",
    "\n",
    "    return messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Połączenie z modelem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja orkiestrująca całość obsługi poleceń uytkownika."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_command(user_command):\n",
    "    \"\"\"\n",
    "    Przetwarza polecenie użytkownika z użyciem GPT-4o oraz function calling.\n",
    "\n",
    "    Parametry:\n",
    "    user_command (str): Polecenie użytkownika.\n",
    "\n",
    "    Zwraca:\n",
    "    tuple: Para (odpowiedź na polecenie użytkownika, aktualizowana historia wiadomości).\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Jesteś pomocnym asystentem. Do obliczeń matematycznych używasz funkcji calulate().\"},\n",
    "        {\"role\": \"user\", \"content\": user_command}\n",
    "    ]\n",
    "    \n",
    "    while True:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=16000\n",
    "        )\n",
    "        \n",
    "        message = response.choices[0].message\n",
    "        \n",
    "        # Jeśli model żąda wykonania funkcji, wykonujemy je i aktualizujemy historię wiadomości\n",
    "        if getattr(message, \"tool_calls\", None):\n",
    "            messages = execute_tool_calls(response, messages)\n",
    "        else:\n",
    "            # Gdy nie ma już żądań funkcji, zwracamy ostateczną odpowiedź modelu.\n",
    "            return message.content, messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wywołajmy to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_command = \"ile to jest 2+2*2?\"\n",
    "# user_command = \"ile to jest 2 do potęgi 3?\"\n",
    "# user_command = \"ile wynosi logarytm naturalny z 20,08553692?\"\n",
    "# user_command = \"ile wynosi logarytm o podstawie 3 z 81?\"\n",
    "\n",
    "response_content, messages = process_user_command(user_command)\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
