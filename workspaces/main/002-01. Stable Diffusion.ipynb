{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stable diffusion (w Hugginface)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej przedstawiono przykład generowania grafik przy użyciu modelu Stable Diffusion. W tym przypadku korzystamy z modelu hostowanego w Hugging Face inference endpoints.\n",
    "\n",
    "### Czym jest Stable Diffusion?\n",
    "\n",
    "Stable Diffusion to model sztucznej inteligencji typu \"text-to-image\" (tekst na obraz), który pozwala generować wysokiej jakości obrazy na podstawie opisu tekstowego. Model wykorzystuje technologię dyfuzji, która stopniowo przekształca szum losowy w obrazy o coraz wyższej jakości. Stable Diffusion został opracowany przez Stability AI i jest jednym z najpopularniejszych modeli do generowania obrazów dostępnych publicznie.\n",
    "\n",
    "### Czym są Hugging Face inference endpoints?\n",
    "\n",
    "Hugging Face inference endpoints to usługa, która umożliwia łatwe i szybkie korzystanie z modeli AI bez konieczności ich lokalnego uruchamiania. Dzięki temu możemy m.in. generować obrazy bezpośrednio z kodu Python, bez potrzeby posiadania własnych zasobów obliczeniowych (GPU) i bez instalowania dodatkowych bibliotek.\n",
    "\n",
    "### Jak skorzystać z Hugging Face inference endpoints?\n",
    "\n",
    "1. Należy utworzyć konto na platformie Hugging Face (huggingface.co)\n",
    "2. Wygenerować token dostępu w ustawieniach konta\n",
    "3. Zainstalować bibliotekę `huggingface_hub` za pomocą pip\n",
    "4. Skonfigurować token jako zmienną środowiskową lub użyć go bezpośrednio w kodzie\n",
    "5. Użyć klasy `InferenceClient` do komunikacji z wybranym modelem\n",
    "\n",
    "W poniższych przykładach pokazano, jak za pomocą prostych instrukcji tekstowych wygenerować różnorodne obrazy, a także jak manipulować parametrami generacji, takimi jak wartość seed czy wzmacnianie/osłabianie określonych cech za pomocą operatorów `+++` oraz `---`, które podnoszą lub obnizaja znaczenie danego fragmentu prompta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import os\n",
    "\n",
    "auth_token = os.getenv('HUGGINGFACE_HUB_TOKEN')\n",
    "client = InferenceClient(\"stabilityai/stable-diffusion-3.5-large\", token=auth_token)\n",
    "\n",
    "# output is a PIL.Image object\n",
    "image = client.text_to_image(\n",
    "    #\"oil painting of sunset beach, waves, impressionist style\",\n",
    "    #\"A photorealistic image of a cat sitting on a windowsill, lit by the light of the setting sun\",\n",
    "    #\"Peppa the Pig and Pikachu drinking vodka from a glass, unreal engine 5 render, photo\",\n",
    "    #\"Aleksander Kwaśniewski pijący drinka w sejmowym barze\",\n",
    "    #negative_prompt=\"distorted, distorted face, deformed, bad anatomy, disfigured, poorly drawn face, pixelart, 2D graphics\",\n",
    "    \"(Strawberry knight)++ with an asparagus sword\",\n",
    "    negative_prompt=\"armored knight\",\n",
    "    #num_inference_steps=20,\n",
    "    #width=1280,\n",
    "    #height=960,\n",
    "    seed=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
