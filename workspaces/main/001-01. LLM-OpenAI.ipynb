{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Korzystanie z API Open AI używając pakietu _openai_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Korzystanie z API OpenAI\n",
    "\n",
    "Standardową metodą korzystania z modeli OpenAI w Pythonie jest pakiet **openai**. Biblioteka ta umożliwia bezpośrednią komunikację z API OpenAI, dając dostęp do wszystkich modeli i funkcjonalności oferowanych przez platformę. Pakiet jest oficjalnie wspierany przez OpenAI i regularnie aktualizowany o nowe funkcje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Inicjalizacja klienta\n",
    "api_key = os.getenv('OPENAI_API_KEY') # pobranie klucza API ze zmiennej środowiskowej\n",
    "client = OpenAI(api_key=api_key) # konfiguracja połączenia z API\n",
    "\n",
    "# Wysłanie zapytania\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Jesteś pomocnym asystentem.\"}, # system prompt - konfiguracja roli jaką model ma pełnić\n",
    "        {\"role\": \"user\", \"content\": \"Napisz wiersz o Gen AI\"}, # konkretne polecenie do wykonania\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=1000\n",
    ")\n",
    "\n",
    "# Wyświetlenie odpowiedzi\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Korzystanie z API Open AI używając pakietu _langchain_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej znajduje się przykład wykonania tego samego zadania co wcześniej, ale przy wykorzystaniu biblioteki LangChain zamiast bezpośredniego API OpenAI.\n",
    "\n",
    "LangChain to popularna biblioteka, która upraszcza pracę z modelami językowymi i tworzy abstrakcję nad różnymi dostawcami API. W teorii, dzięki LangChain można łatwiej budować aplikacje wykorzystujące modele AI, łączyć je w złożone łańcuchy przetwarzania oraz integrować z zewnętrznymi źródłami danych.\n",
    "\n",
    "W praktyce jednak LangChain jest rzadko stosowany w zastosowaniach produkcyjnych. Wiele zespołów preferuje bezpośrednie API dostawców modeli ze względu na większą kontrolę, przewidywalność działania oraz niższe koszty utrzymania. LangChain, pomimo swojej elastyczności, często wprowadza dodatkową warstwę złożoności, która może być problematyczna w środowiskach produkcyjnych wymagających niezawodności i łatwej diagnostyki problemów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import os\n",
    "\n",
    "# Inicjalizacja klienta\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "chat_model = ChatOpenAI(\n",
    "    openai_api_key=api_key,\n",
    "    model_name=\"gpt-4o\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1000\n",
    ")\n",
    "\n",
    "# Wysłanie zapytania\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Jesteś pomocnym asystentem.\"),\n",
    "    (\"human\", \"{prompt}\")\n",
    "])\n",
    "\n",
    "chain = prompt | chat_model\n",
    "\n",
    "result = chain.invoke({\n",
    "    \"prompt\": \"Napisz wiersz o Gen AI\"\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Wyświetlenie odpowiedzi\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
